{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17493,
     "status": "ok",
     "timestamp": 1748477022868,
     "user": {
      "displayName": "Carolyn Hellerqvist Smith",
      "userId": "02107807513435705952"
     },
     "user_tz": 420
    },
    "id": "BzWnh5cRCe-j",
    "outputId": "d3adb6a3-1579-4a47-ca2a-f12b7ac90319"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "# # This mounts your Google Drive to the Colab VM.\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "\n",
    "# # TODO: Enter the foldername in your Drive where you have saved the unzipped\n",
    "# # assignment folder, e.g. 'cs231n/assignments/assignment1/'\n",
    "# FOLDERNAME = 'cs231n/assignments/assignment1/'\n",
    "# FOLDERNAME = 'Coursework/Junior/Spring2025/231N/231_project_research/project_code'\n",
    "# assert FOLDERNAME is not None, \"[!] Enter the foldername.\"\n",
    "\n",
    "# # Now that we've mounted your Drive, this ensures that\n",
    "# # the Python interpreter of the Colab VM can load\n",
    "# # python files from within it.\n",
    "# import sys\n",
    "# sys.path.append('/content/drive/My Drive/{}'.format(FOLDERNAME))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1748477177627,
     "user": {
      "displayName": "Carolyn Hellerqvist Smith",
      "userId": "02107807513435705952"
     },
     "user_tz": 420
    },
    "id": "QTUgbsSC7JoU",
    "outputId": "f061cb7f-809d-496f-f653-9d027b6bec77"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from pointnet_model import MaskedMiniPointNet\n",
    "from preparation import *\n",
    "from data_utils import *\n",
    "from torch.utils.data import DataLoader\n",
    "import pointnet_model\n",
    "import importlib\n",
    "\n",
    "# paths\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1748477178633,
     "user": {
      "displayName": "Carolyn Hellerqvist Smith",
      "userId": "02107807513435705952"
     },
     "user_tz": 420
    },
    "id": "2GQMEUtNGZ9U",
    "outputId": "98188512-3658-4447-bdad-88201147fc7a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 250, 250)\n"
     ]
    }
   ],
   "source": [
    "# Data\n",
    "data = np.random.rand(5, 250, 250) # assume each value in the voxel is a fluorescence intensity\n",
    "data_list = [data] * 50\n",
    "\n",
    "dataset = CubeDataset(data_list)\n",
    "\n",
    "sample = dataset[0]\n",
    "print(sample.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1KF3aNTmXUph"
   },
   "source": [
    "### mini-Pointnet Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1748477180476,
     "user": {
      "displayName": "Carolyn Hellerqvist Smith",
      "userId": "02107807513435705952"
     },
     "user_tz": 420
    },
    "id": "sl8aT6OdIo4m",
    "outputId": "2950d876-d7dc-4a6a-b113-217ec1d76c1e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "torch.Size([2, 5, 250, 250])\n",
      "torch.Size([2, 5, 250, 250])\n",
      "torch.Size([2, 5, 250, 250])\n"
     ]
    }
   ],
   "source": [
    "def custom_collate_fn(batch, mask_percentage=0.6, kernel=12):\n",
    "    cubes = torch.stack([torch.tensor(cube, dtype=torch.float32) for cube in batch])  # (B, Z, Y, X)\n",
    "    B, Z, Y, X = cubes.shape\n",
    "\n",
    "    masks = torch.ones_like(cubes, dtype=torch.float32)\n",
    "    num_blocks = int(mask_percentage * (Z * Y * X) / (kernel ** 3))\n",
    "\n",
    "    visible_cubes = []\n",
    "\n",
    "    for b in range(B):\n",
    "        for _ in range(num_blocks):\n",
    "            zi = np.random.randint(0, max(Z - kernel, 1))\n",
    "            yi = np.random.randint(0, max(Y - kernel, 1))\n",
    "            xi = np.random.randint(0, max(X - kernel, 1))\n",
    "            masks[b, zi:zi + kernel, yi:yi + kernel, xi:xi + kernel] = 0\n",
    "\n",
    "    masked_cubes = cubes * masks\n",
    "\n",
    "    return cubes, masked_cubes, masks  # all are (B, Z, Y, X)\n",
    "\n",
    "sparse_train_loader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=2,\n",
    "    shuffle=True,\n",
    "    collate_fn=custom_collate_fn,\n",
    "    num_workers=0,\n",
    "    pin_memory=False, # ok because we load data on gpu already ?\n",
    "    drop_last=True\n",
    ")\n",
    "\n",
    "\n",
    "cubes, masked_cubes, masks = next(iter(sparse_train_loader))\n",
    "print(len(cubes))\n",
    "print(cubes.shape)\n",
    "print(masked_cubes.shape)\n",
    "print(masks.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1748477181495,
     "user": {
      "displayName": "Carolyn Hellerqvist Smith",
      "userId": "02107807513435705952"
     },
     "user_tz": 420
    },
    "id": "w-LZk7BvKENO"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Making mask\n",
    "cubes, masked_cubes, masks = next(iter(sparse_train_loader))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 25043,
     "status": "ok",
     "timestamp": 1748477207629,
     "user": {
      "displayName": "Carolyn Hellerqvist Smith",
      "userId": "02107807513435705952"
     },
     "user_tz": 420
    },
    "id": "HO0_b4fGKOFT",
    "outputId": "0b2e62fc-2752-4158-84e0-ac323cba658a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 512])\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(pointnet_model)\n",
    "B, Z, Y, X = cubes.shape # (2, 30, 64, 64)\n",
    "\n",
    "visible_cubes = []\n",
    "\n",
    "for cube, mask in zip(cubes, masks):\n",
    "  visible_tokens = cube[mask == 1]\n",
    "  visible_cubes.append(visible_tokens)\n",
    "\n",
    "cubes = cubes.reshape(B, X * Y * Z, 1)  # now (B, 1, N)\n",
    "masks = masks.reshape(B, 1, X*Y*Z)\n",
    "\n",
    "# torch.cuda.empty_cache()\n",
    "\n",
    "mini_pointnet = MaskedMiniPointNet(channels=1, feature_dim=512).to(device)\n",
    "embeddings = mini_pointnet(cubes.to(device), masks.to(device))\n",
    "print(embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2708,
     "status": "ok",
     "timestamp": 1748477226032,
     "user": {
      "displayName": "Carolyn Hellerqvist Smith",
      "userId": "02107807513435705952"
     },
     "user_tz": 420
    },
    "id": "oSzcsnWUf-P-",
    "outputId": "a6f304eb-23f3-4bd8-b8a7-8cba9d51232c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 312500, 512])\n"
     ]
    }
   ],
   "source": [
    "from pos_embed_model import LearnedPositionalEncoder\n",
    "\n",
    "pos_encoder = LearnedPositionalEncoder(num_channels=3, embed_dim=512)\n",
    "pos_encoder.to(device)\n",
    "\n",
    "# Method to get voxel positions\n",
    "# B, Z, Y, X = cubes.shape\n",
    "positions = torch.stack(torch.meshgrid(\n",
    "    torch.arange(Z),\n",
    "    torch.arange(Y),\n",
    "    torch.arange(X),\n",
    "    indexing='ij'  # new PyTorch API to match np.meshgrid\n",
    "), dim=-1).reshape(-1, 3).to(cubes.device)  # shape: (N, 3)\n",
    "\n",
    "#For now, ONLY getting pos embeddings for unmasked voxels\n",
    "# Will do again on masked learnable tokens once they exist :P\n",
    "\n",
    "positions = positions.to(cubes.device).float()\n",
    "pos_input = positions.unsqueeze(0).expand(B, -1, -1)  # (B, N, 3)\n",
    "# voxel_positions = []\n",
    "\n",
    "# for b in range(B):\n",
    "#     mask_flat = masks[b].reshape(-1)  # (Z*Y*X,)\n",
    "#     # pos_visible = positions[mask_flat == 1]  # shape: (N_visible, 3)\n",
    "#     voxel_positions.append(positions)\n",
    "\n",
    "pos_embeds = pos_encoder(pos_input.to(device)) # (B, voxel_ids, embed_dim)\n",
    "print(pos_embeds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n3rUUnydnJz8"
   },
   "outputs": [],
   "source": [
    "from transformer_things import *\n",
    "'''\n",
    "TODO:\n",
    " - make transformer encoder\n",
    " - make inputs to the transformer (figure out how to combine embeddings + pos_embeddings)\n",
    "'''\n",
    "input_dim = pos_embeds.shape[1]\n",
    "num_heads = 8\n",
    "num_layers = 1\n",
    "\n",
    "learning_rate = 1e-3\n",
    "weight_decay = 1.e-4\n",
    "batch_size = 64\n",
    "model = VisionTransformer()\n",
    "\n",
    "\n",
    "encoder_layer = VisionTransformer(input_dim=input_dim, num_heads=num_heads)\n",
    "transformer = TransformerDecoder(decoder_layer, num_layers=num_layers)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
